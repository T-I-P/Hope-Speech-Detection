{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMWFmURgWWFu",
        "outputId": "2c4a976f-471b-45de-8eea-0e7c3e3314aa"
      },
      "source": [
        "# Downloading packages\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcZ6yhCFYbon"
      },
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jxUSr0gYq12"
      },
      "source": [
        "# Read trainig and validation dataset\n",
        "# header_list = [\"text\",\"intent\",\"buffer\"]\n",
        "train = pd.read_csv(\"/content/train_original_sorted_v1.csv\")#, '\\t',header=None,names=header_list)\n",
        "valid = pd.read_csv(\"/content/test_original_sorted_v1.csv\")#, '\\t',header=None,names=header_list)\n",
        "# train = train.drop(labels='buffer',axis=1)\n",
        "# valid = valid.drop(labels='buffer',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hlg5n5wyBN78",
        "outputId": "39aa385a-1d11-4fb8-91f7-e89909713f02"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nice interview</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Serious energy</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Edward  yesss!</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she’s inspiring</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I cackled</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              text  updated\n",
              "0   Nice interview      1.0\n",
              "1   Serious energy     -1.0\n",
              "2  @Edward  yesss!     -1.0\n",
              "3  she’s inspiring      1.0\n",
              "4        I cackled      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uHOS7gyMZB0K",
        "outputId": "38856c54-d372-4ecb-b273-10f74c8d1882"
      },
      "source": [
        "valid.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>love this</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mymo_on  straight.....</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Her face</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm not crying</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Not to Democrats</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     text  updated\n",
              "0               love this      1.0\n",
              "1  Mymo_on  straight.....     -1.0\n",
              "2                Her face     -1.0\n",
              "3          I'm not crying     -1.0\n",
              "4        Not to Democrats     -1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S40VtQzgB4x6"
      },
      "source": [
        "train = train[train['updated']!=16526]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIOunkiO6pXu"
      },
      "source": [
        "valid = valid.drop(labels=['Unnamed: 0', 'intent', 'length'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AupcoTDE1o32"
      },
      "source": [
        "train = train.drop(labels=['Unnamed: 0', 'intent', 'length', 'Unnamed: 5', 'Unnamed: 6'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMmHfcit62MA",
        "outputId": "73ca1b2e-d076-46c1-dd48-c71dca6503fb"
      },
      "source": [
        "valid.updated.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1., -1.,  0.,  2., nan])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ScIiaKU2BGX",
        "outputId": "7a377aa1-2558-44c3-b3a6-b2f50a7e6f5f"
      },
      "source": [
        "train.updated.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1., -1.,  0., nan,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrFGkd9266f5",
        "outputId": "8f18566e-65f0-4762-f4f7-fa9a0a69818c"
      },
      "source": [
        "valid['updated'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERU8owEw2yTV",
        "outputId": "bee8ed65-6231-4ccd-efbe-3321dcd654c3"
      },
      "source": [
        "train['updated'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZjMKl036-tU",
        "outputId": "a133eed5-4e14-4e86-9f86-961e362d002a"
      },
      "source": [
        "valid = valid.dropna()\n",
        "valid = valid.loc[valid['updated']!=2.]\n",
        "valid.updated.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1., -1.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x68Jb-Q5SW4",
        "outputId": "c8b7cf0f-e44d-434c-a852-763c862ebe0c"
      },
      "source": [
        "train = train.dropna()\n",
        "train = train.loc[train['updated']!=2.]\n",
        "train.updated.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1., -1.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr4Rqw1l7MjK"
      },
      "source": [
        "train['updated'] = train['updated'].astype(int)\n",
        "valid['updated'] = valid['updated'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdR05FKb7YdR",
        "outputId": "4dc628ad-87f4-4531-9f2c-644b4d61686e"
      },
      "source": [
        "print(train.updated.unique())\n",
        "print(valid.updated.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 -1  0]\n",
            "[ 1 -1  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v1BPtHy6VNS",
        "outputId": "37ee375e-c4c9-44c3-c811-9c7296d15d6d"
      },
      "source": [
        "print(train.shape)\n",
        "print(valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16509, 2)\n",
            "(2726, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFV-5TIDcjRV"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akovtqQSZk3u"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\",\n",
        "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\",\n",
        "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\",\n",
        "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n",
        "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\",\n",
        "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
        "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\",\n",
        "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
        "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\n",
        "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
        "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n",
        "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
        "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                   \"this's\": \"this is\",\n",
        "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
        "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
        "                       \"here's\": \"here is\",\n",
        "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
        "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
        "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
        "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
        "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n",
        "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
        "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
        "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
        "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"let 's\": \"let us\", \"'em\": \"them\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBKbFVccaeMP",
        "outputId": "9df8d449-9ed7-413f-97d9-5dee10c11992"
      },
      "source": [
        "pip install Unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.5MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjBKqMHNaJ1M"
      },
      "source": [
        "# Code block for data cleaning\n",
        "import codecs\n",
        "import unidecode\n",
        "import re\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def spacy_cleaner(text):\n",
        "    try:\n",
        "        decoded = unidecode.unidecode(codecs.decode(text, 'unicode_escape'))\n",
        "    except:\n",
        "        decoded = unidecode.unidecode(text)\n",
        "    apostrophe_handled = re.sub(\"’\", \"'\", decoded)\n",
        "    expanded = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in apostrophe_handled.split(\" \")])\n",
        "    parsed = nlp(expanded)\n",
        "    final_tokens = []\n",
        "    for t in parsed:\n",
        "        if t.is_punct or t.is_space or t.like_num or t.like_url or str(t).startswith('@'):\n",
        "            pass\n",
        "        else:\n",
        "            if t.lemma_ == '-PRON-':\n",
        "                final_tokens.append(str(t))\n",
        "            else:\n",
        "                sc_removed = re.sub(\"[^a-zA-Z]\", '', str(t.lemma_))\n",
        "                if len(sc_removed) > 1:\n",
        "                    final_tokens.append(sc_removed)\n",
        "    joined = ' '.join(final_tokens)\n",
        "    spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', joined)\n",
        "    return spell_corrected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5x9De54acoh"
      },
      "source": [
        "train['text'] = [spacy_cleaner(t) for t in train.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Ar6anaa4uw"
      },
      "source": [
        "valid['text'] = [spacy_cleaner(t) for t in valid.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-f-reU_c9zM"
      },
      "source": [
        "# Change all the text to lower case. This is required as python interprets 'python', 'Python\" and 'PYTHON' differently\n",
        "train['text'] = [entry.lower() for entry in train['text']]\n",
        "valid['text'] = [entry.lower() for entry in valid['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZuysDAj1c0E0",
        "outputId": "3caa7bed-823e-467a-97b9-5eaa027944be"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice interview</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serious energy</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yess</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shea inspire</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i cackle</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             text  updated\n",
              "0  nice interview        1\n",
              "1  serious energy       -1\n",
              "2            yess       -1\n",
              "3    shea inspire        1\n",
              "4        i cackle        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B7CN0UZdSnd",
        "outputId": "d26db0f2-b9cb-4b78-de8e-55c021b4971d"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       0\n",
              "updated    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJTUostldtvI"
      },
      "source": [
        "train.to_csv('train_cleaned_v2.2.csv')\n",
        "valid.to_csv('valid_cleaned_v2.2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoGO9w4NfV-5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpz4y1HcfViO"
      },
      "source": [
        "## Tokenization / Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rP0JVYCerOq"
      },
      "source": [
        "# Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "train['text']= [word_tokenize(entry) for entry in train['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeIbcum-gV_J"
      },
      "source": [
        "# Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "valid['text']= [word_tokenize(entry) for entry in valid['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdr5kT7qIqA1"
      },
      "source": [
        "type(train.text_final[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bAYCoQRfCDL"
      },
      "source": [
        "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting on training dataset\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(train['text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        stop_words.discard('not')\n",
        "        if word not in stop_words and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    train.loc[index,'text_final'] = str(Final_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTFDAppIKUR8",
        "outputId": "7611ee54-d9f2-45f7-b833-9f64f17a6798"
      },
      "source": [
        "# wordsList = [w for w in train['text'][0]]\n",
        "# a, b = (nltk.pos_tag(wordsList))\n",
        "Final_words = []\n",
        "word_Lemmatized = WordNetLemmatizer()\n",
        "for word, tag in pos_tag(train['text'][0]):\n",
        "    # print(word, tag)\n",
        "    if word not in stopwords.words('english') and word.isalpha():\n",
        "        word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "        Final_words.append(word_Final)\n",
        "print(type(Final_words))\n",
        "train.loc[0, 'text_final'] = Final_words\n",
        "    # break\n",
        "# a, b = pos_tag(valid['text'][0])\n",
        "# print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "oSChcsTNN-Es",
        "outputId": "aaae6cf5-bc84-4176-a111-ba6f0d2f065a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>updated</th>\n",
              "      <th>text_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[nice, interview]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['nice', 'interview']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[serious, energy]</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>['serious', 'energy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[yess]</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>['yes']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[shea, inspire]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['shea', 'inspire']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[i, cackle]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['cackle']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text  updated             text_final\n",
              "0  [nice, interview]      1.0  ['nice', 'interview']\n",
              "1  [serious, energy]     -1.0  ['serious', 'energy']\n",
              "2             [yess]     -1.0                ['yes']\n",
              "3    [shea, inspire]      1.0    ['shea', 'inspire']\n",
              "4        [i, cackle]      0.0             ['cackle']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA5ia-BiOVsc",
        "outputId": "d1a1cdc4-9100-4aa2-9969-0d7b045e1797"
      },
      "source": [
        "type(valid.text_final[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKDA-jDqf6jf"
      },
      "source": [
        "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting on validation dataset\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(valid['text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    valid.loc[index,'text_final'] = str(Final_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5aOuga4C-eh"
      },
      "source": [
        "train.to_csv('train_v1_after_lemm(2000null).csv')\n",
        "valid.to_csv('valid_after_lemm(14null).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRWkTZ8Yghw8",
        "outputId": "665eab95-1660-48cc-ba5d-9bb4e7cc4a31"
      },
      "source": [
        "valid.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text          14\n",
              "updated       14\n",
              "text_final    14\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9g_xpXhBc4"
      },
      "source": [
        "train.dropna(subset=['updated'], inplace=True)\n",
        "train.dropna(subset=['text_final'], inplace=True)\n",
        "valid.dropna(subset=['updated'], inplace=True)\n",
        "valid.dropna(subset=['text_final'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiMvUJhfiWkG",
        "outputId": "2ed54fd5-bfde-415c-cd51-7e193fd69a1e"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text          0\n",
              "updated       0\n",
              "text_final    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqIrcoNFJM_4",
        "outputId": "883b31f2-9dce-4b9d-a5ab-ffbc914032a3"
      },
      "source": [
        "type(train['text_final'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "HTXGXB9niYuR",
        "outputId": "0e719ba0-c806-4c2d-df43-36c645af55dc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>updated</th>\n",
              "      <th>text_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[nice, interview]</td>\n",
              "      <td>1</td>\n",
              "      <td>['nice', 'interview']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[serious, energy]</td>\n",
              "      <td>-1</td>\n",
              "      <td>['serious', 'energy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[yess]</td>\n",
              "      <td>-1</td>\n",
              "      <td>['yes']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[shea, inspire]</td>\n",
              "      <td>1</td>\n",
              "      <td>['shea', 'inspire']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[i, cackle]</td>\n",
              "      <td>0</td>\n",
              "      <td>['cackle']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text  updated             text_final\n",
              "0  [nice, interview]        1  ['nice', 'interview']\n",
              "1  [serious, energy]       -1  ['serious', 'energy']\n",
              "2             [yess]       -1                ['yes']\n",
              "3    [shea, inspire]        1    ['shea', 'inspire']\n",
              "4        [i, cackle]        0             ['cackle']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h92WqYbvEE9Q"
      },
      "source": [
        "train['updated'] = train['updated'].astype(int)\n",
        "valid['updated'] = valid['updated'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcPvio2mipdU"
      },
      "source": [
        "train.to_csv('train_v1_tokenized.csv')\n",
        "valid.to_csv('valid_tokenized_23Apr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyEO-I2liyY6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}